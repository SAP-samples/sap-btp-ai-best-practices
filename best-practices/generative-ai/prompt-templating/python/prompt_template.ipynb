{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e360d12a",
   "metadata": {},
   "source": [
    "# Load Libraries\n",
    "Load libraries and initialize the template for a translation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd74a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "\n",
    "template = Template(\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a helpful translation assistant.\"),\n",
    "        UserMessage(\n",
    "            \"Translate the following text to {{?to_lang}}: {{?text}}\"\n",
    "        ),\n",
    "    ],\n",
    "    defaults=[\n",
    "        TemplateValue(name=\"to_lang\", value=\"German\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3085d459",
   "metadata": {},
   "source": [
    "This template can be used to create translation requests where the language and text to be translated are specified dynamically. The placeholders in the `UserMessage` will be replaced with the actual values provided at runtime, and the default value for the language is set to German."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e564a72",
   "metadata": {},
   "source": [
    "# Define the LLM \n",
    "The `LLM` class is used to configure and initialize a language model for generating text based on specific parameters. In this example, we'll use the gpt-4o model to perform the translation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14843c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "\n",
    "llm = LLM(name=\"gpt-4o\", version=\"latest\", parameters={\"max_tokens\": 256, \"temperature\": 0.2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b27dc6a",
   "metadata": {},
   "source": [
    "# Create an Orchestration Configuration\n",
    "The `OrchestrationConfig` class defines a configuration for integrating various modules, such as templates and language models, into a cohesive orchestration setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d24faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc89e5",
   "metadata": {},
   "source": [
    "# Run the Orchestration Request\n",
    "The `OrchestrationService` class is used to interact with a orchestration service instance by providing configuration details to initiate and manage its operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4654c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Orchestrierungsdienst funktioniert!\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "orchestration_service = OrchestrationService(config=config)\n",
    "result = orchestration_service.run(template_values=[\n",
    "    TemplateValue(name=\"text\", value=\"The Orchestration Service is working!\")\n",
    "])\n",
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbe30ea",
   "metadata": {},
   "source": [
    "# Different `response_format` Parameter Options\n",
    "The `response_format` parameter in `Template` allows the model output to be formatted in several predefined ways, as follows:\n",
    "1. **text**: This is the simplest form where the model's output is generated as plain text. It is suitable for applications that require raw text processing.\n",
    "\n",
    "2. **json_object**: Under this setting, the model's output is structured as a JSON object. This is useful for applications that handle data in JSON format, enabling easy integration with web applications and APIs.\n",
    "\n",
    "3. **json_schema**: This setting allows the model's output to adhere to a defined JSON schema. This is particularly useful for applications that require strict data validation, ensuring the output matches a predefined schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1ca6df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first person to set foot on the moon was astronaut Neil Armstrong. He did so on July 20, 1969, during the Apollo 11 mission.\n"
     ]
    }
   ],
   "source": [
    "# Using text as response format\n",
    "template = Template(\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a helpful assistant.\"),\n",
    "        UserMessage(\"{{?user_query}}\")\n",
    "    ],\n",
    "    response_format=\"text\",\n",
    "    defaults=[\n",
    "        TemplateValue(name=\"user_query\", value=\"Who was the first person on the moon?\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Recreate the config with the new template\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# Call the orchestration service with the new config\n",
    "orchestration_service = OrchestrationService(config=config)\n",
    "result = orchestration_service.run()\n",
    "\n",
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "717ff4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Neil Armstrong\",\n",
      "  \"date\": \"July 20, 1969\",\n",
      "  \"mission\": \"Apollo 11\",\n",
      "  \"nationality\": \"American\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Using json_object as response format\n",
    "template = Template(\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a helpful translation assistant.\"),\n",
    "        UserMessage(\"{{?user_query}}\")\n",
    "    ],\n",
    "    response_format=\"json_object\",\n",
    "    defaults=[\n",
    "        TemplateValue(name=\"user_query\", value=\"Who was the first person on the moon? in json\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Recreate the config with the new template\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# Call the orchestration service with the new config\n",
    "orchestration_service = OrchestrationService(config=config)\n",
    "result = orchestration_service.run()\n",
    "\n",
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f314d7b9",
   "metadata": {},
   "source": [
    "**Important**: When using response_format as json_object, ensure that messages contain the word 'json' in some form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82c54016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"firstName\":\"Neil\",\"lastName\":\"Armstrong\"}\n"
     ]
    }
   ],
   "source": [
    "# Using json_schema as response format\n",
    "from gen_ai_hub.orchestration.models.response_format import ResponseFormatJsonSchema \n",
    "\n",
    "json_schema = {\n",
    "    \"title\": \"Person\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "            \"firstName\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The person's first name.\"\n",
    "        },\n",
    "            \"lastName\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The person's last name.\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "template = Template(\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a helpful translation assistant.\"),\n",
    "        UserMessage(\"{{?user_query}}\")\n",
    "    ],\n",
    "    response_format = ResponseFormatJsonSchema(\n",
    "        name=\"person\", \n",
    "        description=\"person mapping\", \n",
    "        schema=json_schema),\n",
    "    defaults=[\n",
    "        TemplateValue(\n",
    "            name=\"user_query\", \n",
    "            value=\"Who was the first person on the moon?\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Recreate the config with the new template\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# Call the orchestration service with the new config\n",
    "orchestration_service = OrchestrationService(config=config)\n",
    "result = orchestration_service.run()\n",
    "\n",
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
