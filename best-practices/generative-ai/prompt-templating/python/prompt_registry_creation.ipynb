{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc828189",
   "metadata": {},
   "source": [
    "# Load Libraries\n",
    "Load libraries and initialize Prompt Registry Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7748e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PromptTemplateClient initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary classes\n",
    "from gen_ai_hub.proxy import get_proxy_client\n",
    "from gen_ai_hub.prompt_registry.client import PromptTemplateClient\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the proxy client which handles authentication based on env vars/config file\n",
    "proxy_client = get_proxy_client(proxy_version=\"gen-ai-hub\")\n",
    "\n",
    "# Initialize the PromptTemplateClient, passing the proxy client and AI Core base URL\n",
    "# The base URL is typically retrieved from the proxy client's AI Core client instance\n",
    "prompt_registry_client = PromptTemplateClient(proxy_client=proxy_client)\n",
    "\n",
    "print(\"PromptTemplateClient initialized successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae11008",
   "metadata": {},
   "source": [
    "## Creating a Prompt Template\n",
    "Creating a template involves defining its structure using `PromptTemplateSpec` and `PromptTemplate` objects and then calling the `create_prompt_template` method. The `PromptTemplate` object defines the role (system, user, or assistant) and the content for a part of the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90a3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Prompt Template Version with ID: e64aac9c-72f8-4b27-828a-31c5e1592e18\n",
      "Response Message: Prompt updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import models for defining the template structure\n",
    "from gen_ai_hub.prompt_registry.models.prompt_template import PromptTemplateSpec, PromptTemplate\n",
    "\n",
    "# Define the template specification: a list of PromptTemplate objects\n",
    "# This example creates a simple system prompt\n",
    "prompt_template_spec = PromptTemplateSpec(template=[PromptTemplate(role='system',\n",
    "                                                                   content='You are a helpful assistant.')])\n",
    "\n",
    "\n",
    "# Call the create method with scenario, name, version, and the spec\n",
    "# Scenario, name, and version act as identifiers for the template group\n",
    "response = prompt_registry_client.create_prompt_template(\n",
    "    scenario='MyScenario',          # A logical grouping for your templates\n",
    "    name='my_first_template',     # A unique name within the scenario/version\n",
    "    version='1.0.0',              # A version identifier (e.g., semantic version)\n",
    "    prompt_template_spec=prompt_template_spec\n",
    ")\n",
    "\n",
    "# The response contains the unique ID of the created template version\n",
    "template_id = response.id\n",
    "print(f\"Created Prompt Template Version with ID: {template_id}\")\n",
    "print(f\"Response Message: {response.message}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294b0d54",
   "metadata": {},
   "source": [
    "# Retrieving a Prompt Template\n",
    "To fetch the details of a specific template version, use the `get_prompt_template_by_id` method, providing the unique `template_id` obtained during creation or modification. The response object contains the full details of that specific template version, including its specification (spec), identifiers, and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5384b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Template Spec: [PromptTemplate(role='system', content='You are a helpful assistant.')]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the template details using its unique version ID\n",
    "response = prompt_registry_client.get_prompt_template_by_id(template_id)\n",
    "\n",
    "# Access the template specification (structure and content) from the response\n",
    "if response and response.spec:\n",
    "    print(\"Retrieved Template Spec:\", response.spec.template)\n",
    "else:\n",
    "    print(f\"Could not retrieve template with ID: {template_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87311c1",
   "metadata": {},
   "source": [
    "# Modifying a Prompt Template\n",
    "Modifying an existing prompt template in the Prompt Registry using the SDK typically involves creating a new version rather than altering the existing one in place. This is achieved by calling `create_prompt_template` again, using the same `scenario`, `name`, and `version` identifiers, but providing an updated `prompt_template_spec`. This design promotes immutability and ensures a complete history of changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a408fc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Updated Prompt Template Version with ID: 8735721b-4952-4e29-a37d-9bff67041eea\n",
      "Update Message: Prompt updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary models again (if in a new context)\n",
    "from gen_ai_hub.prompt_registry.models.prompt_template import PromptTemplateSpec, PromptTemplate\n",
    "\n",
    "# Define the updated spec with a variable placeholder\n",
    "prompt_template_spec_v2 = PromptTemplateSpec(template=[PromptTemplate(role='system',\n",
    "                                                                      content='You are a helpful assistant for {{ ?topic }}.')])\n",
    "\n",
    "# Call create_prompt_template again with the SAME identifiers but the NEW spec\n",
    "response_v2 = prompt_registry_client.create_prompt_template(\n",
    "    scenario='MyScenario',\n",
    "    name='my_first_template',\n",
    "    version='1.0.0', # Version identifier remains the same for history grouping\n",
    "    prompt_template_spec=prompt_template_spec_v2\n",
    ")\n",
    "\n",
    "# This call returns a NEW unique ID for the updated version\n",
    "input_template_id = response_v2.id\n",
    "print(f\"Created Updated Prompt Template Version with ID: {input_template_id}\")\n",
    "print(\"Update Message:\", response_v2.message) # Confirmation message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752bc2f",
   "metadata": {},
   "source": [
    "It is important to note that `input_template_id` now refers to the latest version containing the variable, while the original `template_id` still points to the first version. The version parameter (`1.0.0` in this case) acts as a label to group these related historical versions together, rather than strictly enforcing semantic versioning rules within the API call itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa4275c",
   "metadata": {},
   "source": [
    "# Viewing Template History\n",
    "To retrieve the history of all versions created for a specific template (grouped by `scenario`, `name`, and `version`), use the `get_prompt_template_history` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72c47240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template History (JSON representation):\n",
      "{\"count\":4,\"resources\":[{\"id\":\"8735721b-4952-4e29-a37d-9bff67041eea\",\"name\":\"my_first_template\",\"version\":\"1.0.0\",\"scenario\":\"MyScenario\",\"creation_timestamp\":\"2025-04-29T12:22:02.720000\",\"managed_by\":\"imperative\",\"is_version_head\":true,\"spec\":{\"template\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant for {{ ?topic }}.\"}],\"defaults\":{},\"additional_fields\":{}}},{\"id\":\"e64aac9c-72f8-4b27-828a-31c5e1592e18\",\"name\":\"my_first_template\",\"version\":\"1.0.0\",\"scenario\":\"MyScenario\",\"creation_timestamp\":\"2025-04-29T12:18:30.758000\",\"managed_by\":\"imperative\",\"is_version_head\":false,\"spec\":{\"template\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant.\"}],\"defaults\":{},\"additional_fields\":{}}},{\"id\":\"d9b51e4e-3314-4a95-b525-70bd726d0958\",\"name\":\"my_first_template\",\"version\":\"1.0.0\",\"scenario\":\"MyScenario\",\"creation_timestamp\":\"2025-04-29T12:03:45.413000\",\"managed_by\":\"imperative\",\"is_version_head\":false,\"spec\":{\"template\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant for {{ ?topic }}.\"}],\"defaults\":{},\"additional_fields\":{}}},{\"id\":\"a01304f1-03aa-4522-bdfe-9d7b26edca84\",\"name\":\"my_first_template\",\"version\":\"1.0.0\",\"scenario\":\"MyScenario\",\"creation_timestamp\":\"2025-04-29T12:03:07.284000\",\"managed_by\":\"imperative\",\"is_version_head\":false,\"spec\":{\"template\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant for {{ ?topic }}.\"}],\"defaults\":{},\"additional_fields\":{}}}]}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the history using the common identifiers\n",
    "history_response = prompt_registry_client.get_prompt_template_history(\n",
    "    scenario='MyScenario',\n",
    "    name='my_first_template',\n",
    "    version='1.0.0'\n",
    ")\n",
    "\n",
    "# The response object contains the history;.json() provides a serializable view\n",
    "# The exact structure should be inspected based on the SDK version\n",
    "# It typically contains a list of versions with their IDs and creation timestamps.\n",
    "print(\"Template History (JSON representation):\")\n",
    "print(history_response.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8428f0e2",
   "metadata": {},
   "source": [
    "# Filling a Prompt Template\n",
    "Once a template with variables is created (like the one with `input_template_id` above), it can be \"filled\" with specific values using the `fill_prompt_template_by_id` method. This substitutes the placeholders with the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e55fe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled Prompt: [PromptTemplate(role='system', content='You are a helpful assistant for chemistry.')]\n"
     ]
    }
   ],
   "source": [
    "# Fill the template version that includes the 'topic' variable\n",
    "fill_response = prompt_registry_client.fill_prompt_template_by_id(\n",
    "    template_id=input_template_id, # Use the ID of the specific version to fill\n",
    "    input_params={\"topic\": \"chemistry\"} # Dictionary mapping variable names to values\n",
    ")\n",
    "\n",
    "# The response contains the 'parsed_prompt' attribute with the filled content\n",
    "if fill_response and fill_response.parsed_prompt:\n",
    "    print(\"Filled Prompt:\", fill_response.parsed_prompt)\n",
    "    # This filled prompt string can now be sent to an LLM via the appropriate SDK client\n",
    "else:\n",
    "    print(f\"Could not fill template with ID: {input_template_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
