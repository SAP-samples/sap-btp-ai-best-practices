{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Grounding on S3 data using SAP Cloud SDK for AI (Python)\n",
    "\n",
    "Purpose: Ground LLM responses on your enterprise data stored in S3, with SAP Document Grounding service using Ochestration module of SAP Cloud SDK (Python). The tutorial demonstrates different steps to set up and implement the grounding service with S3 as a data source.\n",
    "\n",
    "\n",
    "The process consists of three steps:  \n",
    "* Step 1: Upload Documents to S3 bucket  \n",
    "* Step 2: Create Data Repository pointing to S3 bucket  \n",
    "* Step 3: Retrieve most similar documents from Data Repository based on input query and generate augmented answer\n",
    "\n",
    "\n",
    "**Pre-requisites:**\n",
    "* Object Store (S3)\n",
    "* Orchestration service is deployed on AI Core. [SAP Help](https://help.sap.com/docs/ai-launchpad/sap-ai-launchpad/create-deployment-for-orchestration?q=orchestration)\n",
    "\n",
    "\n",
    "**Step 1:**\n",
    "Push your document(s) to the S3 bucket. \n",
    "\n",
    "**Step 2:**\n",
    "Create Generic Secret and a data repository using AI Launchpad with S3 as a source.\n",
    "\n",
    "**Step 3:**\n",
    "Once a data repository is created from S3, use the SDK to retrieve similar documents and complete answer generation.\n",
    "\n",
    "\n",
    "In this tutorial, we will:\n",
    "1. Initialize the Orchestration Service and configure the LLM.\n",
    "2. Define a prompt template for combining the user query with retrieved context.\n",
    "3. Configure grounding with vector data repositories.\n",
    "4. Run the orchestration pipeline and get the grounded response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Load to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtain Object Store Credentials**  \n",
    "* Download S3 credentials from BTP cockpit > BTP subaccount > Space > Instances > ObjectStore > Credentials\n",
    "\n",
    "**AWS CLI Installation and Configuration**  \n",
    "* Install AWS CLI: Download and install the AWS Command Line Interface from the official AWS documentation [Link](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html).\n",
    "* Verify Installation: Check your installation by running:\n",
    "``` sh\n",
    "aws --version\n",
    "```\n",
    "* Configure AWS CLI: Run the configuration command and pass corresponding values from Object Store credentials.\n",
    "``` sh\n",
    "aws configure\n",
    "```\n",
    "\n",
    "**Push Documents to S3**  \n",
    "You can push your documents to S3 bucket. You can optionally put the documents to a sub-directory in the bucket as well.\n",
    "\n",
    "S3 CLI commands:  \n",
    "``` sh\n",
    "aws s3 cp sample.pdf s3://your-bucket-name/sample.pdf\n",
    "OR\n",
    "aws s3 cp . s3://your-bucket-name/ --recursive\n",
    "OR\n",
    "aws s3 cp . s3://your-bucket-name/<optional_path>/ --recursive\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Data Repository on AI Launchpad\n",
    "\n",
    "Create Generic Secret key collection and a Data Repository using that on AI Launchpad. [SAP Help Documentation](https://help.sap.com/docs/ai-launchpad/sap-ai-launchpad/grounding-management).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Retrieve Documents from Data Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1: Initialize Orchestration Service and LLM\n",
    "\n",
    "First, we connect to the **Orchestration Service** using the service URL of your deployment.\n",
    "We also define the **LLM** (in this case `gpt-4o`) with required parameters such as temperature.\n",
    "\n",
    "Replace the placeholder `<your_orchestration_deployment_url>` in the URL with your deployment ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.document_grounding import (GroundingModule, GroundingType, DataRepositoryType,\n",
    "                                                                GroundingFilterSearch, DocumentGrounding,DocumentGroundingFilter)\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "orchestration_service_url = \"<your_orchestration_deployment_url>\"\n",
    "orchestration_service = OrchestrationService(api_url=orchestration_service_url)\n",
    "\n",
    "llm = LLM(\n",
    "    name=\"gpt-4o\",\n",
    "    parameters={\n",
    "        'temperature': 0.0,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Define Prompt Template\n",
    "\n",
    "Here, we define a **prompt template** that instructs the model to:\n",
    "- Take the retrieved `Context` from the document grounding service.\n",
    "- Use it along with the user’s `Question`.\n",
    "\n",
    "This ensures the LLM’s answers are **grounded in enterprise data** rather than generic knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "\n",
    "prompt = Template(messages=[\n",
    "        SystemMessage(\"You are a helpful assistant. Use the given Context information for providing answer to a given query.\"),\n",
    "        UserMessage(\"\"\"Context: {{ ?grounding_response }}\n",
    "                       Question: {{ ?query }}\n",
    "                    \"\"\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3: Configure Document Grounding\n",
    "\n",
    "Next, we configure **document grounding** by linking a **vector data repository**. This ensures that relevant enterprise documents are searched and retrieved for the query.\n",
    "\n",
    "- `data_repositories`: List of repository IDs.\n",
    "- `max_chunk_count`: Controls how many chunks of relevant documents are retrieved.\n",
    "\n",
    "Replace the placeholder (`<repository_id>`) with your actual repository ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [DocumentGroundingFilter(id=\"vector\",\n",
    "                                   data_repositories=[\"<repository_id>\"],\n",
    "                                   search_config=GroundingFilterSearch(max_chunk_count=3),\n",
    "                                   data_repository_type=DataRepositoryType.VECTOR.value\n",
    "                                   )]\n",
    "\n",
    "grounding_config = GroundingModule(\n",
    "            type=GroundingType.DOCUMENT_GROUNDING_SERVICE.value,\n",
    "            config=DocumentGrounding(input_params=[\"query\"], output_param=\"grounding_response\", filters=filters)\n",
    "                   )\n",
    "\n",
    "config = OrchestrationConfig(template=prompt, llm=llm, grounding=grounding_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.4: Run the Orchestration Pipeline\n",
    "\n",
    "Finally, we execute the orchestration pipeline by passing the query. The LLM combines the query with **retrieved context from documents** and returns a **grounded answer**.\n",
    "\n",
    "You should see the response printed below once you run the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def _run_query(query: str, *, _service=orchestration_service, _config=config):\n",
    "    response = _service.run(\n",
    "        config=_config,\n",
    "        template_values=[TemplateValue(\"query\", query)]\n",
    "    )\n",
    "    print(response.orchestration_result.choices[0].message.content)\n",
    "\n",
    "# Use partial so you can call it simply with a query\n",
    "run_query = partial(_run_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effective receptive field is a concept introduced to better understand how deep convolutional neural networks (CNNs) process input images. While the theoretical receptive field of a unit in a CNN is determined by the network's architecture and is supposed to cover a certain area of the input image, the effective receptive field is the actual area that significantly influences the unit's output. \n",
      "\n",
      "Empirical studies have shown that the effective receptive field is smaller than the theoretical receptive field and follows a Gaussian distribution. This means that the central part of the theoretical receptive field has a stronger influence on the unit's output, while the outer parts contribute less. Understanding the effective receptive field is important for tasks like semantic image segmentation, stereo, and optical flow estimation, where each output pixel needs to respond to a sufficiently large area of the input image to capture all relevant information.\n",
      "\n",
      "The study of effective receptive fields provides insights into how deep CNNs work and suggests ways to potentially control and optimize them, such as adjusting network architecture, using nonlinear activations, dropout, sub-sampling, and skip connections.\n"
     ]
    }
   ],
   "source": [
    "run_query(\"what is effective receptive field?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SAP Document AI Embedded Edition refers to a version of the SAP Document AI solution that is integrated within a specific workspace or environment. This edition allows users to utilize the capabilities of SAP Document AI directly within their existing systems or workflows, providing seamless access to document information extraction processes. It enables the automation of extracting relevant information from business documents and matching them to enrichment data records, all within the embedded workspace.\n"
     ]
    }
   ],
   "source": [
    "run_query(\"what is Document AI Embedded?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
