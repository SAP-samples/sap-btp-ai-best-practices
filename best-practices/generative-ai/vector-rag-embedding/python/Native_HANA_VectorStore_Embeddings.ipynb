{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import section\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "from hana_ml import ConnectionContext\n",
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "from gen_ai_hub.proxy.native.openai import embeddings\n",
    "from hdbcli import dbapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Difficulty Level</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What indicates the presence of proteins in a ...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Nutrition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What indicates the presence of starch in food...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Nutrition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can you test for fats in food? To test fo...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Nutrition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is a test for proteins in food items? A ...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Nutrition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are deficiency diseases? Deficiency dise...</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Topic Difficulty Level  \\\n",
       "0   What indicates the presence of proteins in a ...             Easy   \n",
       "1   What indicates the presence of starch in food...             Easy   \n",
       "2   How can you test for fats in food? To test fo...           Medium   \n",
       "3   What is a test for proteins in food items? A ...           Medium   \n",
       "4   What are deficiency diseases? Deficiency dise...             Easy   \n",
       "\n",
       "    Category  \n",
       "0  Nutrition  \n",
       "1  Nutrition  \n",
       "2  Nutrition  \n",
       "3  Nutrition  \n",
       "4     Health  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CSV file\n",
    "csv_path = '../sample_files/science-data-sample.csv'\n",
    "df = pd.read_csv(csv_path, low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "METADATA_COLS = [\"Difficulty Level\", \"Category\"]  # Metadata columns\n",
    "TEXT_COL = \"Topic\"  # Document text\n",
    "VECTOR_COL = \"MY_VECTOR\"  # Embedding column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split text into smaller chunks\n",
    "# Based on the document structure, the chunking strategy can be changed.\n",
    "def chunk_text(text, chunk_size=500):\n",
    "    \"\"\"Splits text into fixed-length chunks.\"\"\"\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data for embeddings\n",
    "processed_rows = []\n",
    "for _, row in df.iterrows():\n",
    "    metadata = {col: str(row[col]) for col in METADATA_COLS}  # Convert metadata to JSON\n",
    "    chunks = chunk_text(str(row[TEXT_COL]))  # Chunk text\n",
    "    for chunk in chunks:\n",
    "        processed_rows.append([chunk, json.dumps(metadata)])  # Store text & metadata JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MY_TEXT</th>\n",
       "      <th>MY_METADATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What indicates the presence of proteins in a ...</td>\n",
       "      <td>{\"Difficulty Level\": \"Easy\", \"Category\": \"Nutr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ter accuracy in scientific investigations. Thi...</td>\n",
       "      <td>{\"Difficulty Level\": \"Easy\", \"Category\": \"Nutr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iscovery of thousands of exoplanets, particula...</td>\n",
       "      <td>{\"Difficulty Level\": \"Easy\", \"Category\": \"Nutr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of experimental techniques allows for more pre...</td>\n",
       "      <td>{\"Difficulty Level\": \"Easy\", \"Category\": \"Nutr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What indicates the presence of starch in food...</td>\n",
       "      <td>{\"Difficulty Level\": \"Easy\", \"Category\": \"Nutr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             MY_TEXT  \\\n",
       "0   What indicates the presence of proteins in a ...   \n",
       "1  ter accuracy in scientific investigations. Thi...   \n",
       "2  iscovery of thousands of exoplanets, particula...   \n",
       "3  of experimental techniques allows for more pre...   \n",
       "4   What indicates the presence of starch in food...   \n",
       "\n",
       "                                         MY_METADATA  \n",
       "0  {\"Difficulty Level\": \"Easy\", \"Category\": \"Nutr...  \n",
       "1  {\"Difficulty Level\": \"Easy\", \"Category\": \"Nutr...  \n",
       "2  {\"Difficulty Level\": \"Easy\", \"Category\": \"Nutr...  \n",
       "3  {\"Difficulty Level\": \"Easy\", \"Category\": \"Nutr...  \n",
       "4  {\"Difficulty Level\": \"Easy\", \"Category\": \"Nutr...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create processed DataFrame\n",
    "processed_df = pd.DataFrame(processed_rows, columns=[\"MY_TEXT\", \"MY_METADATA\"])\n",
    "\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GenAI Hub Proxy Client to access models\n",
    "proxy_client = get_proxy_client('gen-ai-hub')\n",
    "\n",
    "# Function for batch-wise embedding generation for better performance.\n",
    "def get_batch_embeddings(text_list, model=\"text-embedding-ada-002\"): # You may choose a different embedding model available on GenAI Hub\n",
    "    \"\"\"Generates embeddings in batch.\"\"\"\n",
    "    response = embeddings.create(model_name=model, input=text_list)\n",
    "    return [res.embedding for res in response.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process embeddings in batches\n",
    "BATCH_SIZE = 100  # Set batch size\n",
    "vectors = []\n",
    "\n",
    "for i in range(0, len(processed_df), BATCH_SIZE):\n",
    "    batch_texts = processed_df[\"MY_TEXT\"].iloc[i:i+BATCH_SIZE].tolist()\n",
    "    batch_embeddings = get_batch_embeddings(batch_texts)\n",
    "    vectors.extend(batch_embeddings)\n",
    "\n",
    "# Add embeddings to DataFrame\n",
    "processed_df[VECTOR_COL] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.00.000.00.1715685275 (fa/CE2024.2)\n",
      "USR_336RA2ZQ5LAGTHKHCKIYB945E\n"
     ]
    }
   ],
   "source": [
    "# Connect to SAP HANA\n",
    "cc = ConnectionContext(\n",
    "    address=os.environ.get(\"HANA_ADDRESS\"),\n",
    "    port=os.environ.get(\"HANA_PORT\"),\n",
    "    user=os.environ.get(\"HANA_USER\"),\n",
    "    password=os.environ.get(\"HANA_PASSWORD\"),\n",
    "    encrypt=True\n",
    ")\n",
    "print(cc.hana_version())\n",
    "print(cc.get_current_schema())\n",
    "\n",
    "cursor = cc.connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table in SAP HANA\n",
    "TABLE_NAME = \"SCIENCE_DATA_MIT8\"\n",
    "\n",
    "sql_command = f'''\n",
    "CREATE TABLE {TABLE_NAME} (\n",
    "    MY_TEXT NCLOB,\n",
    "    MY_METADATA NCLOB,\n",
    "    MY_VECTOR REAL_VECTOR\n",
    ");\n",
    "'''\n",
    "cursor.execute(sql_command)\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted batch 1/2\n",
      "Completed\n",
      "Inserted batch 2/2\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for insertion\n",
    "processed_df[\"MY_VECTOR\"] = processed_df[\"MY_VECTOR\"].apply(json.dumps) # Change to acceptable format to consider as REAL_VECTOR\n",
    "data = processed_df.values.tolist()\n",
    "\n",
    "# Define batch size\n",
    "BATCH_SIZE = 100 \n",
    "\n",
    "# Insert data into SAP HANA\n",
    "cursor = cc.connection.cursor()\n",
    "sql_insert = f'''\n",
    "    INSERT INTO {TABLE_NAME}\n",
    "    (MY_TEXT, MY_METADATA, MY_VECTOR)\n",
    "    VALUES (?, ?, TO_REAL_VECTOR(?))\n",
    "'''\n",
    "\n",
    "# Process insertion in batches for better performance\n",
    "total_batches = math.ceil(len(data) / BATCH_SIZE)\n",
    "\n",
    "for i in range(total_batches):\n",
    "    batch_data = data[i * BATCH_SIZE : (i + 1) * BATCH_SIZE]\n",
    "    try:\n",
    "        cursor.executemany(sql_insert, batch_data)\n",
    "        cc.connection.commit()\n",
    "        print(f\"Inserted batch {i + 1}/{total_batches}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting batch {i + 1}: {e}\")\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings for a query\n",
    "def get_embedding(query):\n",
    "    \"\"\"\n",
    "    Get embedding vector for a given text.\n",
    "    \"\"\"\n",
    "    embeds = embeddings.create(\n",
    "        model_name=\"text-embedding-ada-002\",\n",
    "        input=query\n",
    "    )\n",
    "    return embeds.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform vector search\n",
    "def run_vector_search(query, cursor, table_name, metric=\"COSINE_SIMILARITY\", k=4):\n",
    "    \"\"\"\n",
    "    Performs vector search on indexed documents.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query_vector = get_embedding(query)\n",
    "        if not query_vector:\n",
    "            raise ValueError(\"Failed to generate query embedding.\")\n",
    "\n",
    "        sort_order = \"DESC\" if metric != \"L2DISTANCE\" else \"ASC\"\n",
    "        sql_query = f'''\n",
    "        SELECT TOP {k} MY_TEXT, MY_METADATA\n",
    "        FROM {table_name}\n",
    "        ORDER BY {metric}(MY_VECTOR, TO_REAL_VECTOR('{query_vector}')) {sort_order}\n",
    "        '''\n",
    "        cursor.execute(sql_query)\n",
    "        return cursor.fetchall()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during vector search: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('al techniques that have significantly impacted the field. By utilizing modern computational tools, we can better understand complex systems and improve predictive modeling. Advanced methodologies, including AI-driven analytics, are reshaping how we interpret large datasets. This enables a more refined understanding of key trends and their broader implications. This research explores new frontiers in scientific discovery, delving into methodologies and experimental techniques that have significan', '{\"Difficulty Level\": \"Easy\", \"Category\": \"Biology\"}')\n",
      "\n",
      "('g modern computational tools, we can better understand complex systems and improve predictive modeling. Advanced methodologies, including AI-driven analytics, are reshaping how we interpret large datasets. This enables a more refined understanding of key trends and their broader implications. This research explores new frontiers in scientific discovery, delving into methodologies and experimental techniques that have sig', '{\"Difficulty Level\": \"Easy\", \"Category\": \"Nutrition\"}')\n",
      "\n",
      "(' can better understand complex systems and improve predictive modeling. Advanced methodologies, including AI-driven analytics, are reshaping how we interpret large datasets. This enables a more refined understanding of key trends and their broader implications.Astrobiologists use various methods to detect potential biosignatures, including spectroscopy, which analyzes the atmospheric composition of exoplanets. The presence of oxygen, methane, and other organic compounds in an exoplanet’s atmosph', '{\"Difficulty Level\": \"Hard\", \"Category\": \"Health\"}')\n",
      "\n",
      "('les a more refined understanding of key trends and their broader implications. The study highlights key advancements in theoretical and applied sciences, emphasizing the importance of interdisciplinary approaches. By integrating data analytics and machine learning, researchers can gain deeper insights into previously unexplored areas. Advanced methodologies, including AI-driven analytics, are reshaping how we interpret large datasets. This enables a more refined understanding of key trends and t', '{\"Difficulty Level\": \"Easy\", \"Category\": \"Nutrition\"}')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute vector search\n",
    "context = run_vector_search(\"What is SAP Business AI?\", cursor, TABLE_NAME, 'COSINE_SIMILARITY', 4)\n",
    "for c in context:\n",
    "    print(c)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
