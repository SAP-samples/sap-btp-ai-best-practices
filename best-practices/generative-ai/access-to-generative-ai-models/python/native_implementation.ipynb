{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and environment keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "Used to load images as base64 strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "import mimetypes\n",
    "\n",
    "def load_image_as_base64(path: str) -> tuple[str, str]:\n",
    "    \"\"\"Return (base64_data, mime_type) for an image file.\"\"\"\n",
    "    image_bytes = Path(path).read_bytes()\n",
    "    mime = mimetypes.guess_type(path)[0] or \"image/png\"\n",
    "    return base64.b64encode(image_bytes).decode(\"utf-8\"), mime\n",
    "\n",
    "def load_image_from_path(path: str) -> bytes:\n",
    "    \"\"\"Return image bytes for an image file.\"\"\"\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        return image_file.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Native Client Integrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon and Anthropic Models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Bedrock Models - text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Fri, 14 Mar 2025 10:40:57 GMT', 'content-type': 'application/json', 'content-length': '213'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': 'The capital of France is Paris.'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 14, 'outputTokens': 10, 'totalTokens': 24}, 'metrics': {'latencyMs': 663}}\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.amazon.clients import Session\n",
    "\n",
    "# Model parameters\n",
    "temperature = 0.6\n",
    "max_Tokens = 1000\n",
    "model = \"anthropic--claude-4-sonnet\"\n",
    "\n",
    "# Create a session with the model\n",
    "bedrock = Session().client(model_name=model)\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": \"What is the capital of France?\"\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "response = bedrock.converse(\n",
    "    messages=messages,\n",
    "    inferenceConfig={\"maxTokens\": max_Tokens, \"temperature\": temperature},\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response['output']['message']['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Bedrock Models - text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 20 Oct 2025 11:51:11 GMT', 'content-type': 'application/json', 'content-length': '738', 'x-aicore-request-id': '34e22184-090c-9a57-b441-700f4fb5d2ef', 'x-upstream-service-time': '4480'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': 'This image shows the SAP logo on a grid background. The logo consists of the letters \"SAP\" in large white text displayed on a blue geometric shape. The background appears to be graph paper or a grid pattern, suggesting this might be from a design or presentation context. SAP is a well-known German multinational software corporation that makes enterprise software to manage business operations and customer relations.'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 1194, 'outputTokens': 83, 'totalTokens': 1277, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 0}, 'metrics': {'latencyMs': 4283}}\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.amazon.clients import Session\n",
    "\n",
    "# Model parameters\n",
    "temperature = 0.6\n",
    "max_Tokens = 1000\n",
    "model = \"anthropic--claude-4-sonnet\"\n",
    "\n",
    "# Create a session with the model\n",
    "bedrock = Session().client(model_name=model)\n",
    "\n",
    "# Load image and convert to base64\n",
    "image_path = \"SAP_logo.png\"\n",
    "fmt = \"png\"  # Format of the image\n",
    "image_data = load_image_from_path(image_path)\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": \"What is the content of the image?\"\n",
    "            },\n",
    "            {\n",
    "                \"image\": {\n",
    "                    \"format\": fmt, \"source\":{\"bytes\": image_data}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "response = bedrock.converse(\n",
    "    messages=messages,\n",
    "    inferenceConfig={\"maxTokens\": max_Tokens, \"temperature\": temperature},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image shows the SAP logo on a grid background. The logo consists of the letters \"SAP\" in large white text displayed on a blue geometric shape. The background appears to be graph paper or a grid pattern, suggesting this might be from a design or presentation context. SAP is a well-known German multinational software corporation that makes enterprise software to manage business operations and customer relations.\n"
     ]
    }
   ],
   "source": [
    "print(response['output']['message']['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Models - text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CSiMjjjEgRVXLVhZVr692UerP2avs', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The capital of France is Paris.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1760959761, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_ee1d74bde0', usage=CompletionUsage(completion_tokens=8, prompt_tokens=24, total_tokens=32, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}, 'prompt_index': 0}])\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.openai import chat\n",
    "\n",
    "# Model parameters\n",
    "temperature = 0.6\n",
    "max_Tokens = 1000\n",
    "model = \"gpt-4o\"  # Also compatible with Meta models like meta-llama3.1-70b-instruct\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "]\n",
    "\n",
    "# Create a session with the model\n",
    "response = chat.completions.create(messages=messages, model=model, temperature=temperature, max_tokens=max_Tokens)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n",
      "Prompt tokens: 24\n",
      "Completion tokens: 8\n",
      "Total tokens: 32\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)\n",
    "usage = getattr(response, \"usage\", None)\n",
    "if usage:\n",
    "    print(f\"Prompt tokens: {usage.prompt_tokens}\")\n",
    "    print(f\"Completion tokens: {usage.completion_tokens}\")\n",
    "    print(f\"Total tokens: {usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Models - text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image contains the logo of SAP, which is a multinational software corporation that makes enterprise software to manage business operations and customer relations. The logo features the letters \"SAP\" in bold white font on a blue background with a triangular shape extending from the top right corner.\n",
      "Prompt tokens: 1138\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-4o\"\n",
    "image_path = \"SAP_logo.png\"\n",
    "base64_data, mime_type = load_image_as_base64(image_path)\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that can answer questions and help with tasks.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"What is the content of the image?\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:{mime_type};base64,{base64_data}\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "response = chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "usage = getattr(response, \"usage\", None)\n",
    "if usage:\n",
    "    print(f\"Prompt tokens: {usage.prompt_tokens}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Models - Reasoning models\n",
    "For reasoning tasks, we can define the \"thinking budget\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning effort: minimal, Time taken: 3.657 seconds\n",
      "Reasoning effort: low, Time taken: 8.252 seconds\n",
      "Reasoning effort: medium, Time taken: 26.256 seconds\n",
      "Reasoning effort: high, Time taken: 21.703 seconds\n",
      "Greenâ€™s theorem is a fundamental result in planar vector calculus that relates a line integral aroun\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "model = \"gpt-5\" \n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is Green theorem?\"}\n",
    "]\n",
    "\n",
    "# Create a session with the model\n",
    "import time\n",
    "\n",
    "# List of reasoning efforts\n",
    "reasoning_efforts = [\"minimal\", \"low\", \"medium\", \"high\"]\n",
    "responses = {}\n",
    "\n",
    "# Time the response for each reasoning effort\n",
    "for effort in reasoning_efforts:\n",
    "    start_time = time.time()\n",
    "    response = chat.completions.create(messages=messages, model=model, reasoning_effort=effort)  # OpenAI reasoning models do not allow temperature or max_tokens settings\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    responses[effort] = {\n",
    "        \"response\": response,\n",
    "        \"time_seconds\": elapsed\n",
    "    }\n",
    "    print(f\"Reasoning effort: {effort}, Time taken: {elapsed:.3f} seconds\")\n",
    "print(response.choices[0].message.content[:300] + '...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Vertex AI Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Vertex AI Models - text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I760054/Documents/programs/Best Practices/sap-btp-ai-best-practices/best-practices/.venv/lib/python3.12/site-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.google_vertexai.clients import GenerativeModel\n",
    "\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "chat = GenerativeModel(model_name)\n",
    "prompt = \"What is the capital of France?\"\n",
    "generation_config = {\"temperature\": 0.}\n",
    "\n",
    "response = chat.generate_content(contents=prompt, generation_config=generation_config)\n",
    "print(response.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Vertex AI Models - text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image displays the **SAP logo** prominently against a grid background.\n",
      "\n",
      "Here's a breakdown of the content:\n",
      "\n",
      "1.  **SAP Logo:** The word \"SAP\" is written in large, bold, white, sans-serif capital letters.\n",
      "2.  **Blue Gradient Background:** The \"SAP\" text is set against a blue gradient shape. This shape transitions from a lighter, brighter blue on the left to a darker blue on the right. The shape is rectangular on the left and bottom, but features a sharp diagonal cut on its right side, giving it a dynamic, almost arrow-like or flag-like appearance.\n",
      "3.  **Grid Background:** The entire logo is placed on a light gray background with a fine white grid pattern, resembling graph paper or a technical design layout.\n",
      "4.  **Ruler Markings:** Along the top and bottom edges of the image, there are subtle ruler-like markings, further emphasizing a design or measurement context.\n",
      "\n",
      "In essence, it's a clean, professional depiction of the SAP logo, presented as if on a design blueprint or grid.\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.google_vertexai.clients import GenerativeModel\n",
    "\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "image_path = \"SAP_logo.png\"\n",
    "base64_data, mime_type = load_image_as_base64(image_path)\n",
    "\n",
    "chat = GenerativeModel(model_name)\n",
    "contents = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "            {\"text\": \"What is the content of the image?\"},\n",
    "            {\"inline_data\": {\"mime_type\": mime_type, \"data\": base64_data}}\n",
    "        ] \n",
    "    }\n",
    "]\n",
    "generation_config = {\"temperature\": 0.}\n",
    "\n",
    "response = chat.generate_content(contents=contents, generation_config=generation_config)\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Vertex AI Models - Multi-modal models\n",
    "Gemini models can use as input not only text and images, but also audio and video, together with text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I760054/Documents/programs/Best Practices/sap-btp-ai-best-practices/best-practices/.venv/lib/python3.12/site-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an analysis of the video for safety violations and recommended measures:\n",
      "\n",
      "**1. Are there any safety violations in the video?**\n",
      "\n",
      "Yes, there are several clear safety violations visible in the video, primarily related to fall protection and housekeeping.\n",
      "\n",
      "**2. Are the railings visible on the stairs? If not, is it dangerous?**\n",
      "\n",
      "No, **railings are not visible on the stairs** leading up to the main platform of the drilling rig. This is **extremely dangerous**. Stairs without handrails significantly increase the risk of falls, especially in an industrial environment where workers may be carrying tools, wearing bulky PPE, or working in potentially slippery conditions (mud, oil, water). Falls from height are a leading cause of serious injuries and fatalities in workplaces.\n",
      "\n",
      "**3. What safety measures should be taken based on what I saw?**\n",
      "\n",
      "Based on the observations, the following safety measures should be implemented:\n",
      "\n",
      "*   **Install Handrails:** Immediately install sturdy handrails on both sides of all stairs and elevated platforms to prevent falls. These should meet regulatory standards for height and strength.\n",
      "*   **Improve Housekeeping:**\n",
      "    *   Clear all loose pipes, hoses, tools, and debris from walkways and work areas to eliminate trip hazards.\n",
      "    *   Ensure proper and secure storage for all materials and equipment, including the metal frame seen near the stairs.\n",
      "*   **Improve Ground Conditions:** Where feasible, level and stabilize the ground in high-traffic work areas to reduce slip and trip hazards. Consider using gravel or other appropriate surfacing.\n",
      "*   **Reinforce PPE Compliance:** While hard hats and high-visibility vests are visible on some workers, ensure all personnel consistently wear all required Personal Protective Equipment (PPE), including safety glasses, gloves, and steel-toed boots, especially when handling materials or operating machinery.\n",
      "*   **Implement Fall Protection for Elevated Work:** For any work at height where permanent railings are not present or temporarily removed, ensure appropriate fall protection systems (e.g., safety harnesses, lanyards, guardrails) are in place and used.\n",
      "*   **Conduct Regular Safety Inspections:** Implement a routine schedule for comprehensive safety inspections to proactively identify and rectify hazards.\n",
      "*   **Provide Safety Training:** Ensure all personnel receive thorough safety training on hazard recognition, fall prevention, proper material handling, and emergency procedures.\n",
      "*   **Establish Clear and Safe Walkways:** Define and maintain clear, unobstructed, and well-lit walkways throughout the site.\n",
      "*   **Secure Stored Materials:** Ensure all stacked pipes and other materials are securely stored on stable racks to prevent shifting, rolling, or collapse.\n",
      "\n",
      "**4. List all safety violations and seconds:**\n",
      "\n",
      "*   **00:00 - 00:59 (Throughout the video): Lack of Handrails on Stairs.**\n",
      "    *   The metal stairs providing access to the elevated platform are clearly visible without any handrails. This is a critical fall hazard.\n",
      "*   **00:00 - 00:59 (Throughout the video): Poor Housekeeping / Trip Hazards.**\n",
      "    *   Loose pipes, hoses, and other debris are scattered on the ground, particularly in the foreground near the base of the stairs and extending into the general work area. This creates significant trip and fall hazards.\n",
      "    *   A loose metal frame/structure is lying on the ground near the bottom of the stairs, indicating improper storage or disused equipment creating a hazard.\n",
      "*   **00:00 - 00:59 (Throughout the video): Uneven Ground Conditions.**\n",
      "    *   The ground surface appears uneven, muddy, and potentially slippery, increasing the risk of slips, trips, and falls for workers moving around the site.\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.google_vertexai.clients import GenerativeModel\n",
    "import base64\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "# Load the media file\n",
    "media_file = open(\"output.mp4\", \"rb\")\n",
    "encoded_media = base64.b64encode(media_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Detect the MIME type of the media file\n",
    "def get_mime_type(file_path: str) -> str:\n",
    "    \"\"\"Determine MIME type based on file extension.\"\"\"\n",
    "    extension = file_path.lower().split('.')[-1]\n",
    "    \n",
    "    mime_types = {\n",
    "        'mp4': 'video/mp4',\n",
    "        'avi': 'video/avi', \n",
    "        'mov': 'video/mov',\n",
    "        'webm': 'video/webm',\n",
    "        'mp3': 'audio/mpeg',\n",
    "        'wav': 'audio/wav',\n",
    "        'flac': 'audio/flac',\n",
    "        'm4a': 'audio/mp4',\n",
    "        'ogg': 'audio/ogg'\n",
    "    }\n",
    "    \n",
    "    return mime_types.get(extension, f'application/{extension}')\n",
    "\n",
    "mime_type = get_mime_type(\"output.mp4\")\n",
    "\n",
    "\n",
    "chat = GenerativeModel(model_name)\n",
    "contents = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "            {\"text\": \"1. Are there any safety violations in the video? 2. Are the railings visible on the stairs? If not, is it dangerous? 3. What safety measures should be taken based on what I saw? 4. List all safety violation and seconds\"},\n",
    "            {\"inline_data\": {\"mime_type\": mime_type, \"data\": encoded_media}}\n",
    "        ] \n",
    "    }\n",
    "]\n",
    "generation_config = {\"temperature\": 0.}\n",
    "\n",
    "response = chat.generate_content(contents=contents, generation_config=generation_config)\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
