{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and environment keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "Used to load images as base64 strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "import mimetypes\n",
    "\n",
    "def load_image_as_base64(path: str) -> tuple[str, str]:\n",
    "    \"\"\"Return (base64_data, mime_type) for an image file.\"\"\"\n",
    "    image_bytes = Path(path).read_bytes()\n",
    "    mime = mimetypes.guess_type(path)[0] or \"image/png\"\n",
    "    return base64.b64encode(image_bytes).decode(\"utf-8\"), mime\n",
    "\n",
    "def load_image_from_path(path: str) -> bytes:\n",
    "    \"\"\"Return image bytes for an image file.\"\"\"\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        return image_file.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Native Client Integrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon and Anthropic Models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Bedrock Models - text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Fri, 14 Mar 2025 10:40:57 GMT', 'content-type': 'application/json', 'content-length': '213'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': 'The capital of France is Paris.'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 14, 'outputTokens': 10, 'totalTokens': 24}, 'metrics': {'latencyMs': 663}}\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.amazon.clients import Session\n",
    "\n",
    "# Model parameters\n",
    "temperature = 0.6\n",
    "max_Tokens = 1000\n",
    "model = \"anthropic--claude-4-sonnet\"\n",
    "\n",
    "# Create a session with the model\n",
    "bedrock = Session().client(model_name=model)\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": \"What is the capital of France?\"\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "response = bedrock.converse(\n",
    "    messages=messages,\n",
    "    inferenceConfig={\"maxTokens\": max_Tokens, \"temperature\": temperature},\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response['output']['message']['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Bedrock Models - text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 20 Oct 2025 11:51:11 GMT', 'content-type': 'application/json', 'content-length': '738', 'x-aicore-request-id': '34e22184-090c-9a57-b441-700f4fb5d2ef', 'x-upstream-service-time': '4480'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': 'This image shows the SAP logo on a grid background. The logo consists of the letters \"SAP\" in large white text displayed on a blue geometric shape. The background appears to be graph paper or a grid pattern, suggesting this might be from a design or presentation context. SAP is a well-known German multinational software corporation that makes enterprise software to manage business operations and customer relations.'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 1194, 'outputTokens': 83, 'totalTokens': 1277, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 0}, 'metrics': {'latencyMs': 4283}}\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.amazon.clients import Session\n",
    "\n",
    "# Model parameters\n",
    "temperature = 0.6\n",
    "max_Tokens = 1000\n",
    "model = \"anthropic--claude-4-sonnet\"\n",
    "\n",
    "# Create a session with the model\n",
    "bedrock = Session().client(model_name=model)\n",
    "\n",
    "# Load image and convert to base64\n",
    "image_path = \"SAP_logo.png\"\n",
    "fmt = \"png\"  # Format of the image\n",
    "image_data = load_image_from_path(image_path)\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": \"What is the content of the image?\"\n",
    "            },\n",
    "            {\n",
    "                \"image\": {\n",
    "                    \"format\": fmt, \"source\":{\"bytes\": image_data}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "response = bedrock.converse(\n",
    "    messages=messages,\n",
    "    inferenceConfig={\"maxTokens\": max_Tokens, \"temperature\": temperature},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image shows the SAP logo on a grid background. The logo consists of the letters \"SAP\" in large white text displayed on a blue geometric shape. The background appears to be graph paper or a grid pattern, suggesting this might be from a design or presentation context. SAP is a well-known German multinational software corporation that makes enterprise software to manage business operations and customer relations.\n"
     ]
    }
   ],
   "source": [
    "print(response['output']['message']['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Models - text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CSiMjjjEgRVXLVhZVr692UerP2avs', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The capital of France is Paris.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1760959761, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_ee1d74bde0', usage=CompletionUsage(completion_tokens=8, prompt_tokens=24, total_tokens=32, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}, 'prompt_index': 0}])\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.openai import chat\n",
    "\n",
    "# Model parameters\n",
    "temperature = 0.6\n",
    "max_Tokens = 1000\n",
    "model = \"gpt-4o\"  # Also compatible with Meta models like meta-llama3.1-70b-instruct\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "]\n",
    "\n",
    "# Create a session with the model\n",
    "response = chat.completions.create(messages=messages, model=model, temperature=temperature, max_tokens=max_Tokens)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n",
      "Prompt tokens: 24\n",
      "Completion tokens: 8\n",
      "Total tokens: 32\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)\n",
    "usage = getattr(response, \"usage\", None)\n",
    "if usage:\n",
    "    print(f\"Prompt tokens: {usage.prompt_tokens}\")\n",
    "    print(f\"Completion tokens: {usage.completion_tokens}\")\n",
    "    print(f\"Total tokens: {usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Models - text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image contains the logo of SAP, which is a multinational software corporation that makes enterprise software to manage business operations and customer relations. The logo features the letters \"SAP\" in bold white font on a blue background with a triangular shape extending from the top right corner.\n",
      "Prompt tokens: 1138\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-4o\"\n",
    "image_path = \"SAP_logo.png\"\n",
    "base64_data, mime_type = load_image_as_base64(image_path)\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that can answer questions and help with tasks.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"What is the content of the image?\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:{mime_type};base64,{base64_data}\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "response = chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "usage = getattr(response, \"usage\", None)\n",
    "if usage:\n",
    "    print(f\"Prompt tokens: {usage.prompt_tokens}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Models - Reasoning models\n",
    "For reasoning tasks, we can define the \"thinking budget\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning effort: minimal, Time taken: 3.657 seconds\n",
      "Reasoning effort: low, Time taken: 8.252 seconds\n",
      "Reasoning effort: medium, Time taken: 26.256 seconds\n",
      "Reasoning effort: high, Time taken: 21.703 seconds\n",
      "Greenâ€™s theorem is a fundamental result in planar vector calculus that relates a line integral aroun\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "model = \"gpt-5\" \n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is Green theorem?\"}\n",
    "]\n",
    "\n",
    "# Create a session with the model\n",
    "import time\n",
    "\n",
    "# List of reasoning efforts\n",
    "reasoning_efforts = [\"minimal\", \"low\", \"medium\", \"high\"]\n",
    "responses = {}\n",
    "\n",
    "# Time the response for each reasoning effort\n",
    "for effort in reasoning_efforts:\n",
    "    start_time = time.time()\n",
    "    response = chat.completions.create(messages=messages, model=model, reasoning_effort=effort)  # OpenAI reasoning models do not allow temperature or max_tokens settings\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    responses[effort] = {\n",
    "        \"response\": response,\n",
    "        \"time_seconds\": elapsed\n",
    "    }\n",
    "    print(f\"Reasoning effort: {effort}, Time taken: {elapsed:.3f} seconds\")\n",
    "print(response.choices[0].message.content[:300] + '...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Vertex AI Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Vertex AI Models - text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I760054/Documents/programs/Best Practices/sap-btp-ai-best-practices/.venv/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.google_vertexai.clients import GenerativeModel\n",
    "\n",
    "model_name = \"gemini-2.5-pro\"\n",
    "\n",
    "chat = GenerativeModel(model_name)\n",
    "prompt = \"What is the capital of France?\"\n",
    "generation_config = {\"temperature\": 0.}\n",
    "\n",
    "response = chat.generate_content(contents=prompt, generation_config=generation_config)\n",
    "print(response.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Vertex AI Models - text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image displays the logo of the company **SAP**.\n",
      "\n",
      "The logo features the letters \"SAP\" in a large, bold, white, sans-serif typeface. These letters are placed on a blue shape that has a gradient, transitioning from a darker blue at the bottom to a lighter, brighter blue at the top. The right side of this blue shape is cut off with a diagonal line sloping downwards.\n",
      "\n",
      "The entire logo is set against a light gray background with a white grid pattern, similar to graph paper, which often suggests precision and design. There are also ruler-like markings along the top and bottom edges of the image.\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.google_vertexai.clients import GenerativeModel\n",
    "\n",
    "model_name = \"gemini-2.5-pro\"\n",
    "image_path = \"SAP_logo.png\"\n",
    "base64_data, mime_type = load_image_as_base64(image_path)\n",
    "\n",
    "chat = GenerativeModel(model_name)\n",
    "contents = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "            {\"text\": \"What is the content of the image?\"},\n",
    "            {\"inline_data\": {\"mime_type\": mime_type, \"data\": base64_data}}\n",
    "        ] \n",
    "    }\n",
    "]\n",
    "generation_config = {\"temperature\": 0.}\n",
    "\n",
    "response = chat.generate_content(contents=contents, generation_config=generation_config)\n",
    "print(response.text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
