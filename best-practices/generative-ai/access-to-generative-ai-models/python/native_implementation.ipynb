{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and environment keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "Used to load images as base64 strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "import mimetypes\n",
    "\n",
    "def load_image_as_base64(path: str) -> tuple[str, str]:\n",
    "    \"\"\"Return (base64_data, mime_type) for an image file.\"\"\"\n",
    "    image_bytes = Path(path).read_bytes()\n",
    "    mime = mimetypes.guess_type(path)[0] or \"image/png\"\n",
    "    return base64.b64encode(image_bytes).decode(\"utf-8\"), mime\n",
    "\n",
    "def load_image_from_path(path: str) -> bytes:\n",
    "    \"\"\"Return image bytes for an image file.\"\"\"\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        return image_file.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Native Client Integrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon and Anthropic Models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Bedrock Models - text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '1f57e1d3-640a-48ec-999b-3890c2efe1f1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 08 Jan 2026 14:18:35 GMT', 'content-type': 'application/json', 'content-length': '345', 'x-aicore-request-id': '57d50cce-0b45-99a4-98bb-a5c016e83ccf', 'x-amzn-requestid': '1f57e1d3-640a-48ec-999b-3890c2efe1f1', 'x-upstream-service-time': '1639'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': 'The capital of France is Paris.'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 14, 'outputTokens': 10, 'totalTokens': 24, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 0}, 'metrics': {'latencyMs': 1490}}\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.amazon.clients import Session\n",
    "\n",
    "# Model parameters\n",
    "temperature = 0.6\n",
    "max_Tokens = 1000\n",
    "model = \"anthropic--claude-4-sonnet\"\n",
    "\n",
    "# Create a session with the model\n",
    "bedrock = Session().client(model_name=model)\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": \"What is the capital of France?\"\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "response = bedrock.converse(\n",
    "    messages=messages,\n",
    "    inferenceConfig={\"maxTokens\": max_Tokens, \"temperature\": temperature},\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response['output']['message']['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Bedrock Models - text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'c2a60192-ef65-4d0f-926e-96987031644c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 08 Jan 2026 14:18:39 GMT', 'content-type': 'application/json', 'content-length': '752', 'x-aicore-request-id': '5cd315ec-7135-9e17-bc02-34ba812db30d', 'x-amzn-requestid': 'c2a60192-ef65-4d0f-926e-96987031644c', 'x-upstream-service-time': '3925'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': 'The image shows the SAP logo on a grid background. The logo consists of the letters \"SAP\" in large white text displayed on a blue geometric shape that resembles a parallelogram or angular banner. The background appears to be graph paper or a technical drawing grid with fine lines. This is the recognizable corporate logo of SAP SE, the German multinational software corporation known for enterprise software and business solutions.'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 1194, 'outputTokens': 88, 'totalTokens': 1282, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 0}, 'metrics': {'latencyMs': 3733}}\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.amazon.clients import Session\n",
    "\n",
    "# Model parameters\n",
    "temperature = 0.6\n",
    "max_Tokens = 1000\n",
    "model = \"anthropic--claude-4-sonnet\"\n",
    "\n",
    "# Create a session with the model\n",
    "bedrock = Session().client(model_name=model)\n",
    "\n",
    "# Load image and convert to base64\n",
    "image_path = \"SAP_logo.png\"\n",
    "fmt = \"png\"  # Format of the image\n",
    "image_data = load_image_from_path(image_path)\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"text\": \"What is the content of the image?\"\n",
    "            },\n",
    "            {\n",
    "                \"image\": {\n",
    "                    \"format\": fmt, \"source\":{\"bytes\": image_data}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "response = bedrock.converse(\n",
    "    messages=messages,\n",
    "    inferenceConfig={\"maxTokens\": max_Tokens, \"temperature\": temperature},\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows the SAP logo on a grid background. The logo consists of the letters \"SAP\" in large white text displayed on a blue geometric shape that resembles a parallelogram or angular banner. The background appears to be graph paper or a technical drawing grid with fine lines. This is the recognizable corporate logo of SAP SE, the German multinational software corporation known for enterprise software and business solutions.\n"
     ]
    }
   ],
   "source": [
    "print(response['output']['message']['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Models - text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Cvl8SEl6DKcBkNyKHd7GGl3ovlTbC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The capital of France is Paris.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1767881920, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_ee1d74bde0', usage=CompletionUsage(completion_tokens=8, prompt_tokens=24, total_tokens=32, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}, 'prompt_index': 0}])\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.openai import chat\n",
    "\n",
    "# Model parameters\n",
    "temperature = 0.6\n",
    "max_Tokens = 1000\n",
    "model = \"gpt-4o\"  # Also compatible with Meta models like meta-llama3.1-70b-instruct\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "]\n",
    "\n",
    "# Create a session with the model\n",
    "response = chat.completions.create(messages=messages, model=model, temperature=temperature, max_tokens=max_Tokens)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n",
      "Prompt tokens: 24\n",
      "Completion tokens: 8\n",
      "Total tokens: 32\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)\n",
    "usage = getattr(response, \"usage\", None)\n",
    "if usage:\n",
    "    print(f\"Prompt tokens: {usage.prompt_tokens}\")\n",
    "    print(f\"Completion tokens: {usage.completion_tokens}\")\n",
    "    print(f\"Total tokens: {usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Models - text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image contains the SAP logo. The logo features the letters \"SAP\" in white, set against a blue background that forms a triangular shape.\n",
      "Prompt tokens: 1138\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-4o\"\n",
    "image_path = \"SAP_logo.png\"\n",
    "base64_data, mime_type = load_image_as_base64(image_path)\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that can answer questions and help with tasks.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"What is the content of the image?\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:{mime_type};base64,{base64_data}\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "response = chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "usage = getattr(response, \"usage\", None)\n",
    "if usage:\n",
    "    print(f\"Prompt tokens: {usage.prompt_tokens}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Models - Reasoning models\n",
    "For reasoning tasks, we can define the \"thinking budget\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning effort: minimal, Time taken: 2.674 seconds\n",
      "Reasoning effort: low, Time taken: 10.278 seconds\n",
      "Reasoning effort: medium, Time taken: 18.988 seconds\n",
      "Reasoning effort: high, Time taken: 27.993 seconds\n",
      "Greenâ€™s theorem is a fundamental result in plane vector calculus that relates a line integral around a closed curve to a double integral over the region it encloses.\n",
      "\n",
      "Statement (circulation form):\n",
      "If C is a positively oriented (counterclockwise), simple, closed, piecewise-smooth curve bounding a reg...\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "model = \"gpt-5\" \n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is Green theorem?\"}\n",
    "]\n",
    "\n",
    "# Create a session with the model\n",
    "import time\n",
    "\n",
    "# List of reasoning efforts\n",
    "reasoning_efforts = [\"minimal\", \"low\", \"medium\", \"high\"]\n",
    "responses = {}\n",
    "\n",
    "# Time the response for each reasoning effort\n",
    "for effort in reasoning_efforts:\n",
    "    start_time = time.time()\n",
    "    response = chat.completions.create(messages=messages, model=model, reasoning_effort=effort)  # OpenAI reasoning models do not allow temperature or max_tokens settings\n",
    "    end_time = time.time()\n",
    "    elapsed = end_time - start_time\n",
    "    responses[effort] = {\n",
    "        \"response\": response,\n",
    "        \"time_seconds\": elapsed\n",
    "    }\n",
    "    print(f\"Reasoning effort: {effort}, Time taken: {elapsed:.3f} seconds\")\n",
    "print(response.choices[0].message.content[:300] + '...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Vertex AI Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Vertex AI Models - text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I760054/Documents/programs/Best Practices/sap-btp-ai-best-practices/best-practices/.venv/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.\n",
      "  from google.cloud.aiplatform.utils import gcs_utils\n",
      "/Users/I760054/Documents/programs/Best Practices/sap-btp-ai-best-practices/best-practices/.venv/lib/python3.12/site-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.google_vertexai.clients import GenerativeModel\n",
    "\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "chat = GenerativeModel(model_name)\n",
    "prompt = \"What is the capital of France?\"\n",
    "generation_config = {\"temperature\": 0.}\n",
    "\n",
    "response = chat.generate_content(contents=prompt, generation_config=generation_config)\n",
    "print(response.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Vertex AI Models - text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image displays the **SAP logo** prominently against a grid background.\n",
      "\n",
      "Here's a breakdown of the content:\n",
      "\n",
      "1.  **SAP Logo:** The word \"SAP\" is written in large, bold, white, sans-serif capital letters.\n",
      "2.  **Blue Gradient Background:** The \"SAP\" text is set against a blue gradient shape. This shape transitions from a lighter, brighter blue on the left to a darker blue on the right. The shape is rectangular on the left and bottom, but features a sharp diagonal cut on its right side, giving it a dynamic, almost arrow-like or flag-like appearance.\n",
      "3.  **Grid Background:** The entire logo is placed on a light gray background with a fine white grid pattern, resembling graph paper or a technical design layout.\n",
      "4.  **Ruler Markings:** Along the top and bottom edges of the image, there are subtle ruler-like markings, further emphasizing a design or measurement context.\n",
      "\n",
      "In essence, it's a clean, professional depiction of the SAP logo, presented as if on a design blueprint or grid.\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.google_vertexai.clients import GenerativeModel\n",
    "\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "image_path = \"SAP_logo.png\"\n",
    "base64_data, mime_type = load_image_as_base64(image_path)\n",
    "\n",
    "chat = GenerativeModel(model_name)\n",
    "contents = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "            {\"text\": \"What is the content of the image?\"},\n",
    "            {\"inline_data\": {\"mime_type\": mime_type, \"data\": base64_data}}\n",
    "        ] \n",
    "    }\n",
    "]\n",
    "generation_config = {\"temperature\": 0.}\n",
    "\n",
    "response = chat.generate_content(contents=contents, generation_config=generation_config)\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Vertex AI Models - Multi-modal models\n",
    "Gemini models can use as input not only text and images, but also audio and video, together with text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the video provided, here's an analysis of the safety aspects:\n",
      "\n",
      "1.  **Are there any safety violations in the video?**\n",
      "    Yes, there are several significant safety violations visible in the video.\n",
      "\n",
      "2.  **Are the railings visible on the stairs? If not, is it dangerous?**\n",
      "    No, the stairs leading up to the elevated platform where the drilling rods are stacked **do not have visible handrails or guardrails**. This is **extremely dangerous**. Without railings, there is a high risk of falls, especially when carrying equipment, in wet or slippery conditions, or if a worker loses balance.\n",
      "\n",
      "3.  **What safety measures should be taken based on what I saw?**\n",
      "    Based on the observations, the following safety measures should be implemented:\n",
      "    *   **Install Handrails and Guardrails:** All stairs, elevated platforms, and open-sided floors or platforms where there is a fall hazard should be equipped with standard handrails and guardrails.\n",
      "    *   **Fall Protection:** For any work at height where guardrails are not feasible, workers must use appropriate personal fall arrest systems (e.g., safety harnesses and lanyards).\n",
      "    *   **Improved Housekeeping:** The work area appears cluttered with pipes, metal frames, and uneven ground. The site needs to be cleared of unnecessary debris and materials to prevent trip hazards.\n",
      "    *   **Clear and Level Walkways:** Establish and maintain clear, level, and stable walkways, especially around heavy equipment and access points. Address any muddy or uneven ground conditions.\n",
      "    *   **Proper Material Storage:** Ensure all pipes and other materials are stacked securely to prevent rolling, falling, or creating obstructions.\n",
      "    *   **Regular Safety Inspections:** Conduct frequent and thorough safety inspections to identify and rectify hazards promptly.\n",
      "    *   **Safety Training:** Ensure all personnel are adequately trained on fall prevention, proper material handling, and general site safety procedures.\n",
      "    *   **PPE Compliance:** While some workers are wearing hard hats and high-visibility vests, ensure all required Personal Protective Equipment (PPE) such as safety footwear, eye protection, and hearing protection (if noise levels warrant it) are worn at all times.\n",
      "\n",
      "4.  **List all safety violation and seconds:**\n",
      "\n",
      "    *   **00:00 - 00:59 (Throughout the video): Lack of Handrails on Stairs.** The stairs providing access to the elevated platform where drilling rods are stored are completely missing handrails, posing a severe fall risk.\n",
      "    *   **00:00 - 00:59 (Throughout the video): Inadequate Fall Protection on Elevated Platform.** Workers are visible on an elevated platform (e.g., near the drilling rig) without apparent guardrails or other fall protection measures, exposing them to falls from height.\n",
      "    *   **00:00 - 00:59 (Throughout the video): Poor Housekeeping/Trip Hazards.** The ground around the work area is uneven and cluttered with various pipes, metal frames, and other materials, creating numerous trip and fall hazards.\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy.native.google_vertexai.clients import GenerativeModel\n",
    "import base64\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "# Load the media file\n",
    "media_file = open(\"output.mp4\", \"rb\")\n",
    "encoded_media = base64.b64encode(media_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Detect the MIME type of the media file\n",
    "def get_mime_type(file_path: str) -> str:\n",
    "    \"\"\"Determine MIME type based on file extension.\"\"\"\n",
    "    extension = file_path.lower().split('.')[-1]\n",
    "    \n",
    "    mime_types = {\n",
    "        'mp4': 'video/mp4',\n",
    "        'avi': 'video/avi', \n",
    "        'mov': 'video/mov',\n",
    "        'webm': 'video/webm',\n",
    "        'mp3': 'audio/mpeg',\n",
    "        'wav': 'audio/wav',\n",
    "        'flac': 'audio/flac',\n",
    "        'm4a': 'audio/mp4',\n",
    "        'ogg': 'audio/ogg'\n",
    "    }\n",
    "    \n",
    "    return mime_types.get(extension, f'application/{extension}')\n",
    "\n",
    "mime_type = get_mime_type(\"output.mp4\")\n",
    "\n",
    "\n",
    "chat = GenerativeModel(model_name)\n",
    "contents = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "            {\"text\": \"1. Are there any safety violations in the video? 2. Are the railings visible on the stairs? If not, is it dangerous? 3. What safety measures should be taken based on what I saw? 4. List all safety violation and seconds\"},\n",
    "            {\"inline_data\": {\"mime_type\": mime_type, \"data\": encoded_media}}\n",
    "        ] \n",
    "    }\n",
    "]\n",
    "generation_config = {\"temperature\": 0.}\n",
    "\n",
    "response = chat.generate_content(contents=contents, generation_config=generation_config)\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
